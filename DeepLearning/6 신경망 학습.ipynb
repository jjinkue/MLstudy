{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a716165b",
   "metadata": {},
   "source": [
    "# 신경망 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63143206",
   "metadata": {},
   "source": [
    "## 단순한 신경망 구현 : Logic Gate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728de5d3",
   "metadata": {},
   "source": [
    "### 필요한 모듈 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c1243bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373f7dfe",
   "metadata": {},
   "source": [
    "### 하이퍼 파라미터(Hyper Parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b2f60d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8104f1",
   "metadata": {},
   "source": [
    "### 유틸 함수들(Util Functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ef7fce16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))\n",
    "\n",
    "def mean_sqaured_error(pred_y,true_y):\n",
    "    return 0.5*(np.sum(true_y - pred_y)**2)\n",
    "\n",
    "def cross_entropy_error(pred_y,true_y):\n",
    "    if true_y.ndim ==1:\n",
    "        true_y = true_y.reshape(1,-1)\n",
    "        pred_y = pred_y.reshape(1,-1)\n",
    "        \n",
    "    delta = 1e-7\n",
    "    return -np.sum(true_y * np.log(pred_y + delta))\n",
    "\n",
    "def cross_entropy_error_for_batch(pred_y,true_y):\n",
    "    if true_y.ndim ==1:\n",
    "        true_y = true_y.reshape(1,-1)\n",
    "        pred_y = pred_y.reshape(1,-1)\n",
    "        \n",
    "    delta = 1e-7\n",
    "    batch_size = pred_y.shape[0]\n",
    "    return -np.sum(true_y * np.log(pred_y + delta)) / batch_size\n",
    "\n",
    "def cross_entropy_error_for_bin(pred_y,true_y):\n",
    "    return 0.5 * np.sum((-true_y * np.log(pred_y) - (1 - true_y) * np.log(1 - pred_y)))\n",
    "\n",
    "def softmax(a):\n",
    "    exp_a = np.exp(a)\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = exp_a / sum_exp_a\n",
    "    \n",
    "    return y\n",
    "\n",
    "def differential(f,x):\n",
    "    eps = 1e-5\n",
    "    diff_value = np.zeros_like(x)\n",
    "    \n",
    "    for i in range(x.shape[0]):\n",
    "        temp_val = x[i]\n",
    "        \n",
    "        x[i] = temp_val + eps\n",
    "        f_h1 = f(x)\n",
    "        \n",
    "        x[i] = temp_val - eps\n",
    "        f_h2 = f(x)\n",
    "        \n",
    "        diff_value[i] = (f_h1 - f_h2) / (2 * eps)\n",
    "        \n",
    "    return diff_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be7bfdd",
   "metadata": {},
   "source": [
    "### 신경망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df5ddf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogicGateNet():\n",
    "    \n",
    "    def __init__(self):\n",
    "        def weight_init():\n",
    "            np.random.seed(1)\n",
    "            weights = np.random.randn(2)\n",
    "            bias = np.random.rand(1)\n",
    "            \n",
    "            return weights, bias\n",
    "        \n",
    "        self.weights, self.bias = weight_init()\n",
    "        \n",
    "    def predict(self,x):\n",
    "        W = self.weights.reshape(-1,1)\n",
    "        b = self.bias\n",
    "        \n",
    "        pred_y = sigmoid(np.dot(x,W)+b)\n",
    "        return pred_y\n",
    "    \n",
    "    def loss(self,x,true_y) : \n",
    "        pred_y = self.predict(x)\n",
    "        return cross_entropy_error_for_bin(pred_y,true_y)\n",
    "    \n",
    "    def get_gradient(self,x,t):\n",
    "        def loss_grad(grad):\n",
    "            return self.loss(x,t)\n",
    "        \n",
    "        grad_W = differential(loss_grad,self.weights)\n",
    "        grad_B = differential(loss_grad,self.bias)\n",
    "        \n",
    "        return grad_W, grad_B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39037b4f",
   "metadata": {},
   "source": [
    "### AND Gate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0dd7fd",
   "metadata": {},
   "source": [
    "#### 모델 생성 및 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a2d25b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs : 100, Cost : 0.688698762848581, Weights : [1.56402489 0.79138771], Bias : [-2.14869146]\n",
      "Epochs : 200, Cost : 0.49469228023287937, Weights : [2.01325161 1.71200974], Bias : [-3.07879437]\n",
      "Epochs : 300, Cost : 0.3920743574674553, Weights : [2.42795372 2.29704769], Bias : [-3.79078865]\n",
      "Epochs : 400, Cost : 0.32578054730528827, Weights : [2.79428901 2.73178113], Bias : [-4.37224115]\n",
      "Epochs : 500, Cost : 0.2786958490607927, Weights : [3.11570431 3.08342195], Bias : [-4.86530315]\n",
      "Epochs : 600, Cost : 0.2433452078259117, Weights : [3.39940551 3.38161091], Bias : [-5.29385366]\n",
      "Epochs : 700, Cost : 0.2157856000923872, Weights : [3.65216893 3.64181093], Bias : [-5.67294341]\n",
      "Epochs : 800, Cost : 0.1936925965494669, Weights : [3.87951811 3.87320526], Bias : [-6.01277885]\n",
      "Epochs : 900, Cost : 0.17559210643186707, Weights : [4.08579293 4.08179208], Bias : [-6.32065064]\n",
      "Epochs : 1000, Cost : 0.1604990115651228, Weights : [4.27438859 4.27176665], Bias : [-6.60197109]\n"
     ]
    }
   ],
   "source": [
    "AND = LogicGateNet()\n",
    "\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "Y = np.array([[0],[0],[0],[1]])\n",
    "\n",
    "train_loss_list = list()\n",
    "\n",
    "for i in range(epochs):\n",
    "    grad_W, grad_B = AND.get_gradient(X,Y)\n",
    "    \n",
    "    AND.weights -= lr*grad_W\n",
    "    AND.bias -= lr*grad_B\n",
    "    \n",
    "    loss = AND.loss(X,Y)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    if i%100 == 99:\n",
    "        print('Epochs : {}, Cost : {}, Weights : {}, Bias : {}'.format(i+1,loss,AND.weights,AND.bias))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a834361",
   "metadata": {},
   "source": [
    "#### 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82751b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00135585]\n",
      " [0.08865214]\n",
      " [0.08886421]\n",
      " [0.8748111 ]]\n"
     ]
    }
   ],
   "source": [
    "print(AND.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0449e86",
   "metadata": {},
   "source": [
    "### OR Gate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f528a8",
   "metadata": {},
   "source": [
    "#### 모델 생성 및 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a6797d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs : 100, Cost : 0.4958958049623752, Weights : [2.45419153 1.40520415], Bias : [-0.14450602]\n",
      "Epochs : 200, Cost : 0.33999100523067505, Weights : [2.98517793 2.39365315], Bias : [-0.67661248]\n",
      "Epochs : 300, Cost : 0.25747786836175185, Weights : [3.44860944 3.08310291], Bias : [-1.03712038]\n",
      "Epochs : 400, Cost : 0.20645212636477486, Weights : [3.85036309 3.60706913], Bias : [-1.30581039]\n",
      "Epochs : 500, Cost : 0.17181024582424712, Weights : [4.19965722 4.02803989], Bias : [-1.5203541]\n",
      "Epochs : 600, Cost : 0.14680779380953535, Weights : [4.50602003 4.37937212], Bias : [-1.69913028]\n",
      "Epochs : 700, Cost : 0.12795648395806816, Weights : [4.77748492 4.68063256], Bias : [-1.85239584]\n",
      "Epochs : 800, Cost : 0.11326452414388091, Weights : [5.02041415 4.94419703], Bias : [-1.9864936]\n",
      "Epochs : 900, Cost : 0.10151135599403104, Weights : [5.23976713 5.17836955], Bias : [-2.10564229]\n",
      "Epochs : 1000, Cost : 0.09190796448433676, Weights : [5.43941599 5.38898714], Bias : [-2.21280016]\n"
     ]
    }
   ],
   "source": [
    "OR = LogicGateNet()\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "Y_2 = np.array([[0],[1],[1],[1]])\n",
    "\n",
    "train_loss_list = list()\n",
    "\n",
    "for i in range(epochs):\n",
    "    grad_W, grad_B = OR.get_gradient(X,Y_2)\n",
    "    \n",
    "    OR.weights -= lr*grad_W\n",
    "    OR.bias -= lr * grad_B\n",
    "    \n",
    "    loss = OR.loss(X,Y_2)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    if i % 100 ==99:\n",
    "        print('Epochs : {}, Cost : {}, Weights : {}, Bias : {}'.format(i+1,loss,OR.weights,OR.bias))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdacef54",
   "metadata": {},
   "source": [
    "#### 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebefa3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0986069 ]\n",
      " [0.95992825]\n",
      " [0.96182368]\n",
      " [0.99981878]]\n"
     ]
    }
   ],
   "source": [
    "print(OR.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33b2c75",
   "metadata": {},
   "source": [
    "### NAND Gate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa504d5b",
   "metadata": {},
   "source": [
    "#### 모델 생성 및 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6532f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs : 100, Cost : 0.7911124259392776, Weights : [-0.49003662 -1.25822733], Bias : [1.74569496]\n",
      "Epochs : 200, Cost : 0.5429873559704227, Weights : [-1.51585766 -1.80296112], Bias : [2.79167048]\n",
      "Epochs : 300, Cost : 0.42119746569927824, Weights : [-2.14663639 -2.26687089], Bias : [3.56530812]\n",
      "Epochs : 400, Cost : 0.3455498971541896, Weights : [-2.60790032 -2.66357416], Bias : [4.18554164]\n",
      "Epochs : 500, Cost : 0.2930680097157151, Weights : [-2.97762276 -3.00565182], Bias : [4.70569391]\n",
      "Epochs : 600, Cost : 0.2542779422995727, Weights : [-3.28924936 -3.30437381], Bias : [5.1544371]\n",
      "Epochs : 700, Cost : 0.22437768084560283, Weights : [-3.55994902 -3.56859574], Bias : [5.54924485]\n",
      "Epochs : 800, Cost : 0.2006150644390317, Weights : [-3.79981845 -3.8050078 ], Bias : [5.90170075]\n",
      "Epochs : 900, Cost : 0.18128040519844302, Weights : [-4.01540776 -4.01865291], Bias : [6.21994667]\n",
      "Epochs : 1000, Cost : 0.16524895981022322, Weights : [-4.21127349 -4.21337527], Bias : [6.50995438]\n"
     ]
    }
   ],
   "source": [
    "NAND = LogicGateNet()\n",
    "\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "Y_3 = np.array([[1],[1],[1],[0]])\n",
    "\n",
    "train_loss_list = list()\n",
    "\n",
    "for i in range(epochs):\n",
    "    grad_W, grad_B = NAND.get_gradient(X,Y_3)\n",
    "    \n",
    "    NAND.weights -= lr*grad_W\n",
    "    NAND.bias -= lr*grad_B\n",
    "    \n",
    "    loss = NAND.loss(X,Y_3)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    if i%100 == 99:\n",
    "        print('Epochs : {}, Cost : {}, Weights : {}, Bias : {}'.format(i+1,loss,NAND.weights,NAND.bias))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4f71cd",
   "metadata": {},
   "source": [
    "#### 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "276fb2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99851366]\n",
      " [0.90859333]\n",
      " [0.90876773]\n",
      " [0.12845438]]\n"
     ]
    }
   ],
   "source": [
    "print(NAND.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6eb3a1",
   "metadata": {},
   "source": [
    "### XOR Gate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdfeeb6",
   "metadata": {},
   "source": [
    "#### 모델 생성 및 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "209f1142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs : 100, Cost : 4.431257974158265, Weights : [ 1.43950113 -0.7957223 ], Bias : [-4.71982194]\n",
      "Epochs : 200, Cost : 9.296669729491885, Weights : [ 1.25716291 -0.97718078], Bias : [-9.43641295]\n",
      "Epochs : 300, Cost : 14.189064482467835, Weights : [ 1.0773283  -1.15613421], Bias : [-14.14965967]\n",
      "Epochs : 400, Cost : 19.075858143100383, Weights : [ 0.89999495 -1.33258498], Bias : [-18.85956311]\n",
      "Epochs : 500, Cost : 23.95681174020937, Weights : [ 0.72516048 -1.50653544], Bias : [-23.56612426]\n",
      "Epochs : 600, Cost : 28.83192680659834, Weights : [ 0.55282254 -1.67798794], Bias : [-28.26934411]\n",
      "Epochs : 700, Cost : 33.70120665498155, Weights : [ 0.38297878 -1.84694485], Bias : [-32.96922362]\n",
      "Epochs : 800, Cost : 38.56465459900839, Weights : [ 0.21562685 -2.01340849], Bias : [-37.66576378]\n",
      "Epochs : 900, Cost : 43.42227393616585, Weights : [ 0.05076442 -2.17738122], Bias : [-42.35896554]\n",
      "Epochs : 1000, Cost : 48.2740679485851, Weights : [-0.11161085 -2.33886535], Bias : [-47.04882985]\n"
     ]
    }
   ],
   "source": [
    "XOR = LogicGateNet()\n",
    "\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "Y_4 = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "train_loss_list = list()\n",
    "\n",
    "for i in range(epochs):\n",
    "    grad_W, grad_B = NAND.get_gradient(X,Y_4)\n",
    "    \n",
    "    XOR.weights -= lr*grad_W\n",
    "    XOR.bias -= lr*grad_B\n",
    "    \n",
    "    loss = XOR.loss(X,Y_4)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    if i%100 == 99:\n",
    "        print('Epochs : {}, Cost : {}, Weights : {}, Bias : {}'.format(i+1,loss,XOR.weights,XOR.bias))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a942f318",
   "metadata": {},
   "source": [
    "#### 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99e6322d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.68937513e-21]\n",
      " [3.55792264e-22]\n",
      " [3.29974851e-21]\n",
      " [3.18217841e-22]]\n"
     ]
    }
   ],
   "source": [
    "print(XOR.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50166a9a",
   "metadata": {},
   "source": [
    "#### 2층 신경망으로 XOR 게이트 구현(1)\n",
    "\n",
    "- 얕은 신경망, Shallow Neural Network\n",
    "\n",
    "- 두 논리게이트(NAND, OR)를 통과하고  \n",
    "  AND 게이트로 합쳐서 구현\n",
    "\n",
    "- 06 신경망 구조 참고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f8792a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[0,0],[1,0],[0,1],[1,1]])\n",
    "Y_5 = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "s1 = NAND.predict(X)\n",
    "s2 = OR.predict(X)\n",
    "X_2 = np.array([s1,s2]).T.reshape(-1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee99247",
   "metadata": {},
   "source": [
    "#### 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bc3a55bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.12866955]\n",
      " [0.79963082]\n",
      " [0.79820836]\n",
      " [0.14232337]]\n"
     ]
    }
   ],
   "source": [
    "print(AND.predict(X_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4273117a",
   "metadata": {},
   "source": [
    "#### 2층 신경망으로 XOR 게이트 구현(2)\n",
    "- 클래스로 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5a0ce4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XORNet():\n",
    "    \n",
    "    def __init__(self):\n",
    "        np.random.seed(1)\n",
    "        \n",
    "        def weight_init():\n",
    "            params = {}\n",
    "            params['w_1'] = np.random.randn(2)\n",
    "            params['b_1'] = np.random.randn(2)\n",
    "            params['w_2'] = np.random.randn(2)\n",
    "            params['b_2'] = np.random.randn(1)\n",
    "            return params\n",
    "        self.params = weight_init()\n",
    "    \n",
    "    def predict(self, x):\n",
    "        W_1, W_2 = self.params['w_1'].reshape(-1,1), self.params['w_2'].reshape(-1,1)\n",
    "        B_1, B_2 = self.params['b_1'], self.params['b_2']\n",
    "        \n",
    "        A1 = np.dot(x,W_1) + B_1\n",
    "        Z1 = sigmoid(A1)\n",
    "        A2 = np.dot(Z1,W_2) + B_2\n",
    "        pred_y = sigmoid(A2)\n",
    "        \n",
    "        return pred_y\n",
    "    \n",
    "    def loss(self,x,true_y):\n",
    "        pred_y = self.predict(x)\n",
    "        return cross_entropy_error_for_bin(pred_y,true_y)\n",
    "    \n",
    "    def get_gredient(self,x,t):\n",
    "        def loss_grad(grad):\n",
    "            return self.loss(x,t)\n",
    "        \n",
    "        grads = {}\n",
    "        grads['w_1'] = differential(loss_grad, self.params['w_1'])\n",
    "        grads['b_1'] = differential(loss_grad, self.params['b_1'])\n",
    "        grads['w_2'] = differential(loss_grad, self.params['w_2'])\n",
    "        grads['b_2'] = differential(loss_grad, self.params['b_2'])\n",
    "        \n",
    "        return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be03722",
   "metadata": {},
   "source": [
    "#### 하이퍼 파라미터(Hyper Parameter)\n",
    "- 재조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "000d7b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a128de",
   "metadata": {},
   "source": [
    "#### 모델 생성 및 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f8c82304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs : 100, Cost :1.204060137701698\n",
      "Epochs : 200, Cost :0.4857492147473586\n",
      "Epochs : 300, Cost :0.2262541169740775\n",
      "Epochs : 400, Cost :0.1394234329457147\n",
      "Epochs : 500, Cost :0.09909684431175998\n",
      "Epochs : 600, Cost :0.07633994334959313\n",
      "Epochs : 700, Cost :0.06187000829415946\n",
      "Epochs : 800, Cost :0.051909765754294006\n",
      "Epochs : 900, Cost :0.04465741332436132\n",
      "Epochs : 1000, Cost :0.039151526245594565\n"
     ]
    }
   ],
   "source": [
    "XOR = XORNet()\n",
    "X = np.array([[0,0],[1,0],[0,1],[1,1]])\n",
    "Y_5 = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "train_loss_list = list()\n",
    "\n",
    "for i in range(epochs):\n",
    "    grads = XOR.get_gredient(X, Y_5)\n",
    "    \n",
    "    for key in ('w_1','b_1','w_2','b_2'):\n",
    "        XOR.params[key] -= lr * grads[key]\n",
    "        \n",
    "    loss = XOR.loss(X,Y_5)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    if i%100 == 99:\n",
    "        print('Epochs : {}, Cost :{}'.format(i+1,loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1031564",
   "metadata": {},
   "source": [
    "#### 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "48be44b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01738781]\n",
      " [0.98277588]\n",
      " [0.97448016]\n",
      " [0.01738411]]\n"
     ]
    }
   ],
   "source": [
    "print(XOR.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431df2b5",
   "metadata": {},
   "source": [
    "## 다중 클래스 분류 : MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19b68fa",
   "metadata": {},
   "source": [
    "### 배치 처리\n",
    "- 학습 데이터 전체를 한번에 진행하지 않고  \n",
    "  일부 데이터(샘플)을 확률적으로 구해서 조금씩 나누어 진행\n",
    "\n",
    "- 확률적 경사 하강법(Stochastic Gradient Descent) 또는  \n",
    "  미니 배치 학습법(mini-batch learning)이라고도 부름"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e53ab3",
   "metadata": {},
   "source": [
    "#### 신경망 구현 : MNIST "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5413b4",
   "metadata": {},
   "source": [
    "#### 필요한 모듈 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c34e5b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745d4ca0",
   "metadata": {},
   "source": [
    "#### 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "53b8c9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31427270",
   "metadata": {},
   "source": [
    "#### 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a296b903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ac5e6c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = x_train[0]\n",
    "print(img.shape)\n",
    "\n",
    "plt.imshow(img,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "78912c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da400e59",
   "metadata": {},
   "source": [
    "#### 데이터 전처리 (Data Preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9a88ebbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_for_mnist(x):\n",
    "    temp = np.zeros((x.shape[0],x[0].size))\n",
    "    \n",
    "    for idx, data in enumerate(x):\n",
    "        temp[idx, : ] = data.flatten()\n",
    "        \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0540f061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "(60000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test = x_train / 255, x_test / 255\n",
    "\n",
    "x_train = flatten_for_mnist(x_train)\n",
    "x_test = flatten_for_mnist(x_test)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "y_train_ohe = tf.one_hot(y_train, depth=10).numpy()\n",
    "y_test_ohe = tf.one_hot(y_test, depth=10).numpy()\n",
    "\n",
    "print(y_train_ohe.shape)\n",
    "print(y_test_ohe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "92179bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0].max(),x_train[0].min())\n",
    "print(y_train_ohe[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3665e1da",
   "metadata": {},
   "source": [
    "#### 하이퍼 파라미터(Hyper Parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "078d576a",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "lr = 0.1\n",
    "batch_size = 100\n",
    "train_size = x_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b7c491",
   "metadata": {},
   "source": [
    "#### 사용되는 함수들(Util Functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8935e9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))\n",
    "\n",
    "def mean_sqaured_error(pred_y,true_y):\n",
    "    return 0.5*(np.sum(true_y - pred_y)**2)\n",
    "\n",
    "def cross_entropy_error(pred_y,true_y):\n",
    "    if true_y.ndim ==1:\n",
    "        true_y = true_y.reshape(1,-1)\n",
    "        pred_y = pred_y.reshape(1,-1)\n",
    "        \n",
    "    delta = 1e-7\n",
    "    return -np.sum(true_y * np.log(pred_y + delta))\n",
    "\n",
    "def cross_entropy_error_for_batch(pred_y,true_y):\n",
    "    if true_y.ndim ==1:\n",
    "        true_y = true_y.reshape(1,-1)\n",
    "        pred_y = pred_y.reshape(1,-1)\n",
    "        \n",
    "    delta = 1e-7\n",
    "    batch_size = pred_y.shape[0]\n",
    "    return -np.sum(true_y * np.log(pred_y + delta)) / batch_size\n",
    "\n",
    "def cross_entropy_error_for_bin(pred_y,true_y):\n",
    "    return 0.5 * np.sum((-true_y * np.log(pred_y) - (1 - true_y) * np.log(1 - pred_y)))\n",
    "\n",
    "def softmax(a):\n",
    "    exp_a = np.exp(a)\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = exp_a / sum_exp_a\n",
    "    \n",
    "    return y\n",
    "\n",
    "def differential_1d(f,x):\n",
    "    \n",
    "    eps = 1e-5\n",
    "    diff_value = np.zeros_like(x)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(x.shape[0]):\n",
    "        temp_val = x[i]\n",
    "        \n",
    "        x[i] = temp_val + eps\n",
    "        f_h1 = f(x)\n",
    "        \n",
    "        x[i] = temp_val - eps\n",
    "        f_h2 = f(x)\n",
    "        \n",
    "        diff_value[i] = (f_h1 - f_h2) / (2 * eps)\n",
    "        \n",
    "    return diff_value\n",
    "\n",
    "def differential_2d(f,X):\n",
    "    if X.ndim == 1:\n",
    "        return differential_1d(f,X)\n",
    "    else:\n",
    "        grad = np.zeros_like(X)\n",
    "        \n",
    "        for idx, x in enumerate(X):\n",
    "            grad[idx] = differential_1d(f,x)\n",
    "        \n",
    "        return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013e2d3b",
   "metadata": {},
   "source": [
    "#### 2층 신경망으로 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d8dc6c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        def weight_init(input_nodes,hidden_nodes,output_units):\n",
    "            np.random.seed(777)\n",
    "            \n",
    "            params = {}\n",
    "            params['w_1'] = 0.01 * np.random.randn(input_nodes,hidden_nodes)\n",
    "            params['b_1'] = np.zeros(hidden_nodes)\n",
    "            params['w_2'] = 0.01 * np.random.randn(hidden_nodes, output_units)\n",
    "            params['b_2'] = np.zeros(output_units)\n",
    "            return params\n",
    "        \n",
    "        self.params = weight_init(784, 64, 10)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        W_1, W_2 = self.params['w_1'], self.params['w_2']\n",
    "        B_1, B_2 = self.params['b_1'], self.params['b_2']\n",
    "        \n",
    "        A1 = np.dot(x,W_1) + B_1\n",
    "        Z1 = sigmoid(A1)\n",
    "        A2 = np.dot(Z1,W_2) + B_2\n",
    "        pred_y = softmax(A2)\n",
    "        \n",
    "        return pred_y\n",
    "    \n",
    "    def loss(self,x,true_y):\n",
    "        pred_y = self.predict(x)\n",
    "        return cross_entropy_error_for_bin(pred_y,true_y)\n",
    "    \n",
    "    def accuracy(self, x, true_y):\n",
    "        pred_y = self.predict(x)\n",
    "        y_argmax = np.argmax(pred_y, axis=1)\n",
    "        t_argmax = np.argmax(true_y, axis=1)\n",
    "        \n",
    "        accuracy = np.sum(y_argmax == t_argmax) / float(x.shape[0])\n",
    "        \n",
    "        return accuracy\n",
    "    \n",
    "    def get_gradient(self,x,t):\n",
    "        def loss_grad(grad):\n",
    "            return self.loss(x,t)\n",
    "        \n",
    "        grads = {}\n",
    "        grads['w_1'] = differential_2d(loss_grad, self.params['w_1'])\n",
    "        grads['b_1'] = differential_2d(loss_grad, self.params['b_1'])\n",
    "        grads['w_2'] = differential_2d(loss_grad, self.params['w_2'])\n",
    "        grads['b_2'] = differential_2d(loss_grad, self.params['b_2'])\n",
    "        \n",
    "        return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4f6c81",
   "metadata": {},
   "source": [
    "#### 모델 생성 및 학습\n",
    "- 시간 많이 소요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5eb0cab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f7698d668644444bb500488d510bbf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs : 1, Cost : 465.7337030177362, Train Accuracy : 0.10441666666666667, Test Accuracy : 0.1028\n",
      "Epochs : 2, Cost : 361.8357552598185, Train Accuracy : 0.09751666666666667, Test Accuracy : 0.0974\n",
      "총 학습시간 : 245.949s \n"
     ]
    }
   ],
   "source": [
    "model = MyModel()\n",
    "\n",
    "train_loss_list = list()\n",
    "train_acc_list = list()\n",
    "test_acc_list = list()\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "start_time = time.time()\n",
    "for i in tqdm(range(epochs)):\n",
    "    \n",
    "    batch_idx = np.random.choice(train_size,batch_size)\n",
    "    x_batch = x_train[batch_idx]\n",
    "    y_batch = y_train_ohe[batch_idx]\n",
    "                \n",
    "    grads = model.get_gradient(x_batch,y_batch)\n",
    "    \n",
    "    for key in grads.keys():\n",
    "        model.params[key] -= lr * grads[key]\n",
    "        \n",
    "    loss = model.loss(x_batch, y_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    train_accuracy = model.accuracy(x_train, y_train_ohe)\n",
    "    test_accuracy = model.accuracy(x_test, y_test_ohe)\n",
    "    train_acc_list.append(train_accuracy)\n",
    "    test_acc_list.append(test_accuracy)\n",
    "    \n",
    "    print('Epochs : {}, Cost : {}, Train Accuracy : {}, Test Accuracy : {}'.format(i+1, loss, train_accuracy, \n",
    "                                                                                  test_accuracy))\n",
    "    \n",
    "end_time = time.time()\n",
    "\n",
    "print('총 학습시간 : {:.3f}s '.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a155e6",
   "metadata": {},
   "source": [
    "### 모델의 결과\n",
    "- 모델은 학습이 잘 될 수도, 잘 안될 수도 있음\n",
    "\n",
    "- 만약, 학습이 잘 되지 않았다면,  \n",
    "  학습이 잘 되기 위해서 어떠한 조치를 취해야 하는가?\n",
    "  - 다양한 학습관련 기술이 존재"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
