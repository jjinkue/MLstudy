{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "950aca74",
   "metadata": {},
   "source": [
    "### 과대적합과 과소적합"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41e8f94",
   "metadata": {},
   "source": [
    "<br>**최적화(optimization)**는 가능한 훈련 데이터에서 최고의 성능을 얻으려고 모델을 조정하는 과정<br><br>\n",
    "**일반화(generalization)**는 훈련된 모델이 이전에 본 적 없는 데이터에서 얼마나 잘 수행되는지를 의미함<br><br>\n",
    "\n",
    "훈련 데이터의 손실이 낮아질수록 테스트 데이터의 손실도 낮아짐. 이를 곧 **'과소적합'**(underfitting)이라고 함<br><br>\n",
    "\n",
    "훈련 데이터에서 여러 번 반복 학습하고 나면 어느 시점부터 일반화 성능이 높아지지 않음. <br>\n",
    "즉, 모델이 과대적합되기 시작함.\n",
    "\n",
    "<br><br> 모델이 관련성이 없고 좋지 못한 패턴을 훈련 데이터에서 학습하지 못하도록 하려면 가장 좋은 방법은 **더 많은 훈련데이터를 수집하는 것**!!\n",
    "\n",
    "<br>만일 데이터를 수집하는 것이 불가능할 경우 차선책으로 모델이 수용할 수 있는 정보의 양을 조절하거나 저장할 수 있는 정보에 제약을 가하는 것. 이를 곧 **규제**(regularization)이라고 함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232155fe",
   "metadata": {},
   "source": [
    "#### 네트워크 크기 축소"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33260039",
   "metadata": {},
   "source": [
    "원본 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67989db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu',input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(16, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f83e0e",
   "metadata": {},
   "source": [
    "원본 모델에서 더 작은 용량의 모델로 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2e57090",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(6, activation='relu',input_shape=(10000,)))\n",
    "model.add(layers.Dense(6, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4ecc64",
   "metadata": {},
   "source": [
    "- 원본 모델과 수정한 모델을 비교하면 원본 모델이 더 빠르게 과대적합이 시작함.\n",
    "- 훈련 손실의 경우 원본 모델이 빠르게 0에 가까워지는 것을 확인할 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96aab15b",
   "metadata": {},
   "source": [
    "#### 가중치 규제 추가 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba24fb9",
   "metadata": {},
   "source": [
    "<br> **오캄의 면도날**(Occam's razor) : 복수의 이론 중에서 더 적은 가정이 필요요한 간단한 설명이 옳을 것이라는 이론<br><br>\n",
    "신경망 모델에서도 마찬가지로 간단한 모델이 복잡한 모델보다 덜 과대적합될 가능성이 높음!!<br><br>\n",
    "과대적합을 완화하기 위한 일반적인 방법은 **가중치 규제**(weight regularization)<br><br>\n",
    "- L1규제 : 가중치의 절댓값에 비용하는 비용이 추가 \n",
    "- L2규제 : 가중치의 제곱에 비례하는 비용이 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f47a3b0",
   "metadata": {},
   "source": [
    "모델에 L2 가중치 추가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf7aac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001),\n",
    "                       activation='relu',input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001),\n",
    "                       activation='relu'))\n",
    "model.add(layers.Dense(16, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6155e92b",
   "metadata": {},
   "source": [
    "케라스에서는 L2규제 대신 아래와 같이 가중치 규제 중 하나를 사용할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7592f5e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.regularizers.L1L2 at 0x7f6ac0107df0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "regularizers.l1(0.001) # L1규제\n",
    "\n",
    "regularizers.l1_l2(l1=0.001,l2=0.001) # L1과 L2 규제 병행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc3a175",
   "metadata": {},
   "source": [
    "#### 드롭아웃 추가 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bda951",
   "metadata": {},
   "source": [
    "<br> 드롭아웃은 신경망을 위해 사용되는 규제 기법 중 가장 효과적이고 널리 사용되는 방법 중 하나 <br><br>\n",
    "네트워크 층에서 드롭아웃을 적용하면 훈련하는 동안 무작위로 층의 일부 출력 특성을 제외시킴<br><br>\n",
    "\n",
    "드롭아웃의 추가를 통해 층의 출력 값에 노이즈를 추가하여 중요하지 않은 우연한 패턴을 깨트림<br><br>\n",
    "\n",
    "아래 코드를 통해 Dropout추가 가능<br><br>\n",
    "```\n",
    "model.add(layers.Dropout(0.5))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f32212",
   "metadata": {},
   "source": [
    "네트워크에서 드롭아웃 추가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f06a4002",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu',input_shape=(10000,)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ce2995",
   "metadata": {},
   "source": [
    "### 정리 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c549c53",
   "metadata": {},
   "source": [
    "신경망에서 과대적합을 방지하기 위해 가장 널리 사용하는 방법은<br><br>\n",
    "\n",
    "- 더 많은 훈련데이터를 수집\n",
    "- 네트워크 용량을 감소\n",
    "- 가중치 규제를 추가\n",
    "- 드랍아웃을 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19bf9f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
